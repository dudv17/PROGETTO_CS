{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80216850",
   "metadata": {},
   "source": [
    "# DOGS ADOPTIONS PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8677a",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dcfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e03145",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ff990",
   "metadata": {},
   "source": [
    "**Importing the 'dogs', 'dog_travel' and 'NST_EST' dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d51fd6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs = pd.read_csv(\"adoptions/dogs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e8d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel = pd.read_csv(\"adoptions/dogTravel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f923d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NST_EST = pd.read_csv(\"adoptions/NST-EST2021-POP.csv\", header=None)\n",
    "NST_EST.columns = ['state', 'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69eb179",
   "metadata": {},
   "source": [
    "**The str.replace() method replaces any dots in the population column with an empty string, and then the astype() method converts the resulting strings to integers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8c6aa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NST_EST['population'] = NST_EST['population'].str.replace('.', '', regex=False).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab2c82",
   "metadata": {},
   "source": [
    "**Importing the 'states' dataset, which contains all the USA states and their abbreviation (this dataset will be used in exercise 5 and 9)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2b1d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'zip_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'zip_end'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m states \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madoptions/states.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_end\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_end\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_end\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_end\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      6\u001b[0m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_start\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_end\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'zip_end'"
     ]
    }
   ],
   "source": [
    "states = pd.read_csv(\"adoptions/states.csv\", sep=';')\n",
    "\n",
    "states['zip_end'] = states['zip_end'].fillna(0)\n",
    "states['zip_end'] = states['zip_end'].astype(int)\n",
    "\n",
    "states['zip_start'] = states['zip_end'].fillna(0)\n",
    "states['zip_start'] = states['zip_end'].astype(int)\n",
    "\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89965d8e",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0005360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a007e2da",
   "metadata": {},
   "source": [
    "**Cleaning the 'name' column in the 'dogs' dataframe**\n",
    "\n",
    "**In the following rows, column 'status' contains the dog name in a \"dirty\" form and also what should be contained in the 'description' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_and_desc = dogs[dogs['status'] != 'adoptable']['name'] \n",
    "names_and_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046d4df",
   "metadata": {},
   "source": [
    "**Isolate the names in \"dirty\" form in a separate list:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f240e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_names = []\n",
    "for name_desc in names_and_desc:\n",
    "    dirty_names.append(name_desc.split(sep=\",\")[0])\n",
    "dirty_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e85c7",
   "metadata": {},
   "source": [
    "There are two pattern in the diry names: \n",
    "1. name \\\\\\nickname-char\\\\\\\\\"\n",
    "2. \\\\\\nickname-char\\\\\\\\\"\n",
    "\n",
    "in the first case we want to isolate the name\n",
    "\n",
    "in the second case we isolate the nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48504ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomi = []\n",
    "for name in dirty_names:\n",
    "    match = re.split(r'[:\\\\]', name)\n",
    "    if match[0] == '':                  #pattern n° 2 -> the 'match' list contains only the nickname\n",
    "        nomi.append(match[1].strip())   #remove leading or trailing spaces with 'strip()' and appending to the 'nomi' list\n",
    "    else:                               #pattern n° 1 -> the 'match' list contains only the nickname\n",
    "        nomi.append(match[0].strip()) \n",
    "dogs_clean = dogs.copy(deep=True)       #create a copy of the 'dogs' dataframe ('dogs_clean') that is completely \n",
    "                                        #indipendent from it (thanks to deep=True): if you modify 'dogs' this will\n",
    "                                        # not affect 'dogs_clean'\n",
    "\n",
    "dogs_clean.loc[dogs_clean['status'] != 'adoptable', 'name'] = nomi \n",
    "# ^ assign the cleaned names in the column 'name' of dogs_clean\n",
    "\n",
    "dogs_clean[dogs_clean['status'] != 'adoptable']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b26e8",
   "metadata": {},
   "source": [
    "**Shift the columns corresponding to the previous names from 'status' to 'accessed' of one to the right**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b54343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_clean.loc[dogs_clean['status'] != 'adoptable','status':'accessed'] = dogs_clean.loc[dogs_clean['status'] != 'adoptable','status':'accessed'].shift(1, axis=1)\n",
    "dogs_clean.loc[dogs_clean['status'] != 'adoptable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500257c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_clean.loc[17610:17630,'status':'accessed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bb709",
   "metadata": {},
   "source": [
    "# 1. Extract all dogs with status that is not adoptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c2abe",
   "metadata": {},
   "source": [
    "**Dataset before cleaning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1db918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs[dogs['status'] != 'adoptable'][['id', 'name', 'status']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d48d01",
   "metadata": {},
   "source": [
    "**Cleaned dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cadfd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_ad_dogs = dogs_clean[dogs_clean['status'] != 'adoptable'][['id', 'name', 'status']]\n",
    "not_ad_dogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47dab2",
   "metadata": {},
   "source": [
    "**Dataset before cleaning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b02a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs[dogs['status'] != 'adoptable'][['status']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2177b",
   "metadata": {},
   "source": [
    "**Cleaned dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421564e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_clean[dogs_clean['status'] != 'adoptable'][['status']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67241a2",
   "metadata": {},
   "source": [
    "# 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41df784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "breed_counts = dogs.groupby('breed_primary').count()[['id']].rename(columns={'id':'counts'})#.reset_index()[['breed_primary','counts']]\n",
    "breed_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248470d3",
   "metadata": {},
   "source": [
    "# 3. For each (primary) breed, determine the ratio between the number of dogs of Mixed Breed and those not of Mixed Breed. Hint: look at the secondary_breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef836d7a",
   "metadata": {},
   "source": [
    "**METHOD 1:**\n",
    "\n",
    "**Considering the 'breed_secondary' column: if it contains the text 'Mixed Breed' it means that the dog is of mixed breed, otherwise it is not**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568a391",
   "metadata": {},
   "source": [
    "**Selecting the 'Mixed Breed' dogs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_for_breed = dogs_clean[dogs_clean['breed_secondary'] == 'Mixed Breed'].groupby('breed_primary', as_index=False).count()\n",
    "mixed_for_breed['n_mixed'] = mixed_for_breed['id']\n",
    "mixed_for_breed = mixed_for_breed[['breed_primary', 'n_mixed']]\n",
    "mixed_for_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0a7a4",
   "metadata": {},
   "source": [
    "**Selecting the 'Not of Mixed Breed' dogs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_mixed_for_breed = dogs_clean[dogs_clean['breed_secondary'] != 'Mixed Breed'].groupby('breed_primary', as_index=False).count()\n",
    "not_mixed_for_breed['n_not_mixed'] = not_mixed_for_breed['id']\n",
    "not_mixed_for_breed = not_mixed_for_breed[['breed_primary', 'n_not_mixed']]\n",
    "not_mixed_for_breed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2582632",
   "metadata": {},
   "source": [
    "**Merging the tables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7aacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_mixed = pd.merge(mixed_for_breed, not_mixed_for_breed, on='breed_primary')\n",
    "ratio_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da603220",
   "metadata": {},
   "source": [
    "**Calculating the ratio between 'mixed' and 'not_mixed'**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c73025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratio_mixed['ratio_M_notM'] = ratio_mixed['n_mixed']/not_mixed_for_breed['n_not_mixed']\n",
    "ratio_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae50d0",
   "metadata": {},
   "source": [
    "**METHOD 2:**\n",
    "\n",
    "**Considering the 'breed_mixed' column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473cb6c",
   "metadata": {},
   "source": [
    "**If True it means that the dog is of mixed breed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99934e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_breed = dogs_clean.where(dogs_clean['breed_mixed']== True).groupby('breed_primary').size().reset_index(name='mixed')\n",
    "mixed_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059c9db",
   "metadata": {},
   "source": [
    "**If False it means that the dog is not of mixed breed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_mixed_breed = dogs.where(dogs['breed_mixed'] == False).groupby('breed_primary').size().reset_index(name='not_mixed')\n",
    "not_mixed_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98cca3c",
   "metadata": {},
   "source": [
    "**We merge and calculate the ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_ratio = pd.merge(mixed_breed, not_mixed_breed, on='breed_primary')\n",
    "breed_ratio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef769a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_ratio['ratio'] = breed_ratio['mixed'] / breed_ratio['not_mixed']\n",
    "breed_ratio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429da65",
   "metadata": {},
   "source": [
    "\n",
    "# 4. For each (primary) breed, determine the earliest and the latest posted timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032ca5c",
   "metadata": {},
   "source": [
    "**We check and convert the 'posted' type to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['posted'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['posted'] = pd.to_datetime(dogs_clean['posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58922889",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean.dropna(subset=['posted'], inplace=True)\n",
    "len(dogs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1029f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['posted'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c0aaf",
   "metadata": {},
   "source": [
    "**We find the min and the max for each 'breed_primary' and merge them in a single table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_timestamps = dogs_clean.groupby(by='breed_primary')['posted'].min().reset_index()\n",
    "latest_timestamps = dogs_clean.groupby(by='breed_primary')['posted'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c940dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.merge(earliest_timestamps, latest_timestamps, on=\"breed_primary\").rename(columns={'posted_x':'earliest_timestamp', 'posted_y':'latest_timestamp'})\n",
    "timestamps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3f494",
   "metadata": {},
   "source": [
    "# 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12123c57",
   "metadata": {},
   "source": [
    "**We count the values of Females and Males for each State and then calculate the sex imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30767994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_counts = dogs_clean.groupby('contact_state')['sex'].value_counts().unstack()\n",
    "sex_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fde2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_counts['sex_imbalance'] = sex_counts['Male'] - sex_counts['Female']\n",
    "sex_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b118a38",
   "metadata": {},
   "source": [
    "**Using the 'states' df, we find the full name of the state with the largest sex imbalance, through the 'abbreviation' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47676646",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_imbalance_state = sex_counts['sex_imbalance'].idxmax()\n",
    "max_imbalance_state_name = states.loc[states['abbreviation'] == max_imbalance_state].values[0][0]\n",
    "print(f'The state with the largest sex imbalance is: {max_imbalance_state_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b7f0a",
   "metadata": {},
   "source": [
    "# 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c5272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_stay_cost = dogs_clean.groupby(['age', 'size'], as_index=False)[['age','size','stay_duration','stay_cost']].mean(['stay_duration','stay_cost'])\n",
    "mean_stay_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35eec3",
   "metadata": {},
   "source": [
    "**Apply a categorization to the values contained in the 'age' column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0583104",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stay_cost['age'] = pd.Categorical(mean_stay_cost['age'], \n",
    "                                       categories=['Baby', 'Young', 'Adult', 'Senior'],\n",
    "                                       ordered=True\n",
    "                                      )\n",
    "\n",
    "mean_stay_cost['size'] = pd.Categorical(mean_stay_cost['size'], \n",
    "                                        categories = ['Small', 'Medium', 'Large', 'Extra Large'],\n",
    "                                        ordered=True\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59ec74",
   "metadata": {},
   "source": [
    "**Renaming the columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10140128",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stay_cost.rename(columns={\"stay_duration\": \"mean_stay_duration\", \"stay_cost\": \"mean_stay_cost\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77734a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_stay_cost.groupby(by=['age', 'size'])[['mean_stay_duration', 'mean_stay_cost']].mean() \n",
    "#use 'age' and 'size' as index and sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0973",
   "metadata": {},
   "source": [
    "# 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef948a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3ec4f",
   "metadata": {},
   "source": [
    "**We count the number of travels for each 'id' and select only the ones >= 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_viaggi = dog_travel.groupby('id').count()\n",
    "n_viaggi.rename(columns={'index' : 'n_travels'}, inplace=True)\n",
    "n_viaggi = n_viaggi[['n_travels']]\n",
    "n_viaggi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_viaggi = n_viaggi[n_viaggi['n_travels'] >= 3]\n",
    "n_viaggi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad3afb",
   "metadata": {},
   "source": [
    "**Merging with the 'dogs_clean' df, we can find the 'breed_primary'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a829be",
   "metadata": {},
   "outputs": [],
   "source": [
    "atleast_3 = pd.merge(n_viaggi, dogs_clean, on='id')\n",
    "atleast_3[['id', 'n_travels', 'breed_primary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f068529",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(atleast_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22757dd",
   "metadata": {},
   "source": [
    "# 8. Fix the travels table so that the correct state is computed from the manual and the found fields. If manual is not missing, then it overrides what is stored in found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e71202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function takes two strings in input 'found' and 'manual'\n",
    "and returns 'found' if 'manual' is Null\n",
    "returns 'manual' otherwise\n",
    "\"\"\"\n",
    "def correct_state(found, manual):\n",
    "    if pd.isna(manual):\n",
    "        return found\n",
    "    else:\n",
    "        return manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124634a",
   "metadata": {},
   "source": [
    "**Apply the above function to every row of the 'dog_travel' dataframe using the lambda row sintax and storing the result in a list called 'lista'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = dog_travel.apply(lambda row: correct_state(row['found'], row['manual']), axis=1)\n",
    "lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdeb00",
   "metadata": {},
   "source": [
    "**Replacing the values in 'lista'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel['found'] = lista\n",
    "dog_travel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85a601",
   "metadata": {},
   "source": [
    "# 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d24eb0",
   "metadata": {},
   "source": [
    "**We merge the 'NST_EST' df and the 'states' df to have a complete df with 'abbreviation', 'state', 'population'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bcdc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NST = pd.merge(NST_EST, states, on='state')\n",
    "NST[['abbreviation', 'state', 'population']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3c739",
   "metadata": {},
   "source": [
    "**We count the number of travels for each state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e1d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "travels_count = dog_travel.groupby('contact_state').size().reset_index(name='travels')\n",
    "travels_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d317374d",
   "metadata": {},
   "source": [
    "**We notice that '17325' correspond to the zip code of Pennsylvania (PA), so we replace it and run the count again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_travel['contact_state'].replace('17325', 'PA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a32fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "travels_count = dog_travel.groupby('contact_state').size().reset_index(name='travels')\n",
    "travels_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a1b05",
   "metadata": {},
   "source": [
    "**We merge as to have a df with 'contact_state', 'population', 'travels' so now we can calculate the ratio in a new column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ratio = pd.merge(NST, travels_count, left_on='abbreviation', right_on='contact_state')[['contact_state','population', 'travels']]\n",
    "state_ratio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ratio['ratio'] = state_ratio['travels'] / state_ratio['population']\n",
    "state_ratio.rename(columns = {'contact_state' : 'state'}, inplace = True)\n",
    "state_ratio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27ae4a",
   "metadata": {},
   "source": [
    "# 10. For each dog, compute the number of days from the posted day to the day of last access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1720b6c",
   "metadata": {},
   "source": [
    "**Control data types of 'posted' and 'accessed' columns and changing them to 'datetime' if they are not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['posted'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca363ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['accessed'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60471677",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['accessed'] = pd.to_datetime(dogs_clean['accessed'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.dropna(subset=['accessed'], inplace=True)\n",
    "len(dogs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b41080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['posted'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs_clean['accessed'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beecd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf583f8",
   "metadata": {},
   "source": [
    "**Converting from a 'datetime' to a 'date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['posted'] = dogs_clean['posted'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['accessed'] = dogs_clean['accessed'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433421e",
   "metadata": {},
   "source": [
    "**Calculating the days between 'posted' and 'accessed'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['days_between'] = (dogs_clean['accessed'] - dogs_clean['posted']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06481189",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_between = dogs_clean[['id', 'posted', 'accessed', 'days_between']]\n",
    "days_between"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d764d3",
   "metadata": {},
   "source": [
    "# 11. Partition the dogs according to the number of weeks from the posted day to the day of last access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec8acf",
   "metadata": {},
   "source": [
    "**We devide the days that have passed by 7, as to have the number of weeks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f41b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['weeks_between'] = (dogs_clean['accessed'] - dogs_clean['posted']).dt.days/7\n",
    "dogs_clean['weeks_between'] = dogs_clean['weeks_between'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42aa47",
   "metadata": {},
   "source": [
    "**We then bin the number of weeks into pre-defined ranges, and save to a new column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d970d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_clean['weeks_range'] = pd.cut(dogs_clean['weeks_between'], bins=[-np.inf, 1, 4, 8, 12, 16, 24, 25, 52, np.inf], labels=['< 1 week', '1-4 weeks', '4-8 weeks', '8-12 weeks', '12-16 weeks', '16 weeks - 6 months', '> 6 months', '1 year', '> 1 year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_between = dogs_clean[['id', 'posted', 'accessed', 'days_between', 'weeks_between', 'weeks_range']]\n",
    "weeks_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4e6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92eee49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794f075a",
   "metadata": {},
   "source": [
    "# 12. Find for duplicates in the dogs dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6317489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop any rows with missing values\n",
    "dogs_sub = dogs_clean.dropna(subset=['breed_primary', 'description', 'sex'])\n",
    "dogs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe085c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the description field\n",
    "def preprocess_description(desc):\n",
    "    if pd.isna(desc):\n",
    "        return []\n",
    "    desc = re.sub(r'\\W+', ' ', desc.lower())\n",
    "    return desc.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1cf11",
   "metadata": {},
   "source": [
    "^ this function takes a string as input and returns a list of preprocessed words. The preprocessing steps include converting the string to lowercase, removing any non-alphanumeric characters, and splitting the string into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ce5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the percentage of shared words between two descriptions\n",
    "\n",
    "def shared_word_percentage(desc1, desc2):\n",
    "    set1 = set(desc1)\n",
    "    set2 = set(desc2)\n",
    "    if len(set1) == 0 or len(set2) == 0:\n",
    "        return 0.0\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921739c",
   "metadata": {},
   "source": [
    "^ this function is defined to calculate the percentage of shared words between two descriptions. This is done by first converting the descriptions to sets of words, and then calculating the intersection and union of the sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_sub.loc[:, 'description_processed'] = dogs_sub['description'].apply(preprocess_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411b27e",
   "metadata": {},
   "source": [
    "^ the 'description_processed' column in the dogs_clean DataFrame is created by applying the 'preprocess_description' function to the 'description' column using the 'apply()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the processed descriptions and their corresponding IDs\n",
    "desc_dict = dict(zip(dogs_sub['id'], dogs_sub['description_processed']))\n",
    "#desc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835e23c",
   "metadata": {},
   "source": [
    "^ a dictionary called 'desc_dict' is created to store the processed descriptions and their corresponding IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a hash table to store the processed descriptions and their corresponding IDs\n",
    "desc_hash = {}\n",
    "for i, desc in enumerate(dogs_sub['description_processed']):\n",
    "    desc_hash[hash(' '.join(desc))] = desc_hash.get(hash(' '.join(desc)), []) + [dogs_sub.iloc[i]['id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866c769",
   "metadata": {},
   "source": [
    "^ a hash table called 'desc_hash' is created to store the processed descriptions and their corresponding IDs. The hash table is constructed by iterating over the 'description_processed' column in the dogs_sub DataFrame, and using the 'hash()' function to generate a hash value for each description. The hash value is used as a key in the desc_hash dictionary, and the corresponding ID is added to a list of IDs associated with that hash value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the duplicate pairs using the hash table\n",
    "duplicate_pairs = []\n",
    "for i, desc in enumerate(dogs_sub['description_processed']):\n",
    "    desc_hash[hash(' '.join(desc))].remove(dogs_sub.iloc[i]['id'])\n",
    "    for j in desc_hash[hash(' '.join(desc))]:\n",
    "        if dogs_sub.iloc[i]['breed_primary'] == dogs_sub[dogs_sub['id'] == j]['breed_primary'].values[0] and \\\n",
    "           dogs_sub.iloc[i]['breed_secondary'] == dogs_sub[dogs_sub['id'] == j]['breed_secondary'].values[0] and \\\n",
    "           dogs_sub.iloc[i]['sex'] == dogs_sub[dogs_sub['id'] == j]['sex'].values[0]:\n",
    "            shared_words = shared_word_percentage(desc, desc_dict[j])\n",
    "            if shared_words >= 0.9:\n",
    "                duplicate_pairs.append((dogs_sub.iloc[i]['id'], j))\n",
    "    desc_hash[hash(' '.join(desc))].append(dogs_sub.iloc[i]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d506752",
   "metadata": {},
   "source": [
    "^ a loop is used to iterate over the 'description_processed' column in the dogs_sub DataFrame. For each record, the ID is removed from the list of IDs associated with its hash value in the desc_hash dictionary. Then, a nested loop is used to compare the current record to all other records in the desc_hash dictionary with the same hash value. If the current record and another record have the same breeds and sex, and their shared word percentage is at least 90%, then they are considered a duplicate pair and their IDs are added to the duplicate_pairs list.\n",
    "\n",
    "^^ execution time: ~ 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb677d",
   "metadata": {},
   "source": [
    "**We save the pairs in a new df and populate with the corresponding values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b92ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_duplicate_pairs = pd.DataFrame(duplicate_pairs, columns=['id_1', 'id_2'])\n",
    "df_duplicate_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_sub[dogs_sub['id'] == 44696946][['id', 'breed_primary', 'breed_secondary', 'sex', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_sub[dogs_sub['id'] == 45301676][['id', 'breed_primary', 'breed_secondary', 'sex', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'df_duplicate_pairs' with 'dogs' to populate it with the corresponding values\n",
    "df_duplicate_pairs = pd.merge(df_duplicate_pairs, dogs, left_on='id_1', right_on='id')\n",
    "df_duplicate_pairs = df_duplicate_pairs[['id_1', 'id_2', 'breed_primary', 'breed_secondary', 'sex', 'description']]\n",
    "df_duplicate_pairs = pd.merge(df_duplicate_pairs, dogs, suffixes=['_1', '_2'], left_on='id_2', right_on='id')\n",
    "df_duplicate_pairs = df_duplicate_pairs[['id_1', 'id_2', 'breed_primary_1', 'breed_primary_2', 'breed_secondary_1', 'breed_secondary_2', 'sex_1', 'sex_2', 'description_1', 'description_2']]\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df_duplicate_pairs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
